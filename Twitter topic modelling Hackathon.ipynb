{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   <h1><center>Twitter topic classification Hackathon</center></h1>\n",
    "   <h2><center>Includes Topic Modelling</center><h2>\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all the standard libraries , \n",
    "## Pandas, numpy arrays, Regular Expression, NLTK for text processing, Sklearn for Classifiction models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1><center>###  Importing the CSV file from the Local PC ###</center></h1>\n",
    "<end>Data set has been read in to the DataFrame variable twd(Twitter Data)</end>\n",
    "\n",
    "<end> Please paste the link of your file in the same function</end>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twd=pd.read_csv(r'C:/Users/pc/Desktop/Hackathon/twcs/twcs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Displaying first five observations of the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here in this Data set we need the text data and either it is a good or bad statement by customer\n",
    "  - ##### Hence discarding the rest of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'author_id', 'inbound', 'created_at', 'text',\n",
       "       'response_tweet_id', 'in_response_to_tweet_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping the unecessary columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "twd.drop(['tweet_id', 'author_id', 'created_at','response_tweet_id', 'in_response_to_tweet_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   Dataset after removing the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inbound                                               text\n",
       "0    False  @115712 I understand. I would like to assist y...\n",
       "1     True      @sprintcare and how do you propose we do that\n",
       "2     True  @sprintcare I have sent several private messag...\n",
       "3    False  @115712 Please send us a Private Message so th...\n",
       "4     True                                 @sprintcare I did."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the total number of observations and columns present in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2811774, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Only Ten thousand observations has been taken to develope the model. \n",
    "######  The New data frame variable name  is \"twd_sample \"(twitter data Sample) consisting 10,000 observations.\n",
    "######  It restricted because of memory limitations , if it is not so, u can pass the whole data set like \"\"\"twd.iloc[:,:].copy()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "twd_sample=twd.iloc[2070000:2080000,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070000</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares Sneha, when i call some i hear you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070001</th>\n",
       "      <td>False</td>\n",
       "      <td>@336024 We apologies for the trouble. We would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070002</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares u irritating idiots, y the fuck pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070003</th>\n",
       "      <td>False</td>\n",
       "      <td>@307570 Sorry we gave you a chance of being up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070004</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares He told me - Sir don't repeat your...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text\n",
       "2070000     True  @idea_cares Sneha, when i call some i hear you...\n",
       "2070001    False  @336024 We apologies for the trouble. We would...\n",
       "2070002     True  @idea_cares u irritating idiots, y the fuck pr...\n",
       "2070003    False  @307570 Sorry we gave you a chance of being up...\n",
       "2070004     True  @idea_cares He told me - Sir don't repeat your..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking whether our dataset consists of NaNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inbound    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Counting the number of Postive and Negative comments avialable in the DataFrame  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5428\n",
       "False    4572\n",
       "Name: inbound, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample['inbound'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing the generalised function to remove the uncessary characters, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(input_text):\n",
    "    \n",
    "    lema=WordNetLemmatizer()                                ### World Lematizer \n",
    "\n",
    "    input_text = re.sub('<.*?>', ' ', (input_text))         ### Removing html and xml tags in text data and replacing with blanks\n",
    "    input_text = str(input_text).replace(\"<br />\", \" \")     ###  Removing Line Breakage tags\n",
    "    input_text = str(input_text).replace(\",\", \"\")           ### Removing punctuations and replacing with blanks\n",
    "    input_text = str(input_text).replace(\"\\'\" ,\"\")\n",
    "    input_text = str(input_text).replace(\"\\\\\", \"\")\n",
    "    input_text = str(input_text).replace(\"-\", \"\")\n",
    "    input_text = str(input_text).replace(\".\", \"\")\n",
    "    input_text  =re.sub(r'\\s+', ' ',input_text )            ### Removing multiple spaces\n",
    "     \n",
    "    \n",
    "    input_text = re.sub(\"[^a-zA-Z]\",\" \",input_text)         ## Considering only alphabets rest is replaced by spaces\n",
    "    input_text = input_text.lower()                         ## Lowering the text\n",
    "    words      = input_text.split()                         ## Splitting the text\n",
    "    noise_free_words =  [w for w in words if w not in set(stopwords.words('english'))] ## Removing Stop words\n",
    "    lower_words=[lema.lemmatize(w) for w in noise_free_words]                          ## Apllying Lemmatization to the words                        \n",
    "    lower_words=' '.join(lower_words)\n",
    "                                   \n",
    "    return lower_words   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the Data into 70% Train, 30% Test by passing text data in to  \n",
    "##### Independent variable \"X\" and True or False in to Targer variable \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X=twd_sample['text']\n",
    "y=twd_sample['inbound']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing the noise in the Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.apply(remove_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2079069    centurylinkhelp calling calling simple account...\n",
       "2072603    sorry hear please dm u information experience ...\n",
       "2077738    apology kazuma happy look please follow dm u a...\n",
       "2071579                           wed like look device using\n",
       "2075058    day ported number vodafone call failing cancel...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing the noise in the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.apply(remove_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2076252              glad could help gillian good day steven\n",
       "2074684    british airway would nice id settle reply dm f...\n",
       "2071731    birthday lunch help one fave sandwich mcrib po...\n",
       "2074742                             british airway ba lhrdxb\n",
       "2074521                             weve received dm respond\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting of Words in the observations to matrix representation using Tfidf Vectorizer\n",
    "- Word Frequencies with TfidfVectorizer\n",
    "- This stands for “Term Frequency – Inverse Document Frequency\" which are the components of the resulting -  scores assigned to each word.\n",
    "- Inverse Document Frequency: This downscales words that appear a lot across documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_tr=X_train\n",
    "X_ts=X_test\n",
    "y_tr=y_train\n",
    "y_ts=y_test\n",
    "\n",
    "tf=TfidfVectorizer(max_df=0.85, min_df=3,max_features=1600, stop_words='english')\n",
    "\n",
    "X_tr=tf.fit_transform(X_tr).toarray()\n",
    "\n",
    "X_ts=tf.fit_transform(X_ts).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ##### Note if X_train and X_test column \"(m,n)\"  \"(k,n)\" dimension is not matching, \n",
    "  - please change the max_features in Tfidf Vectorizer paramter in the above\n",
    "  - Remember please give high features  to learn more from the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is : (7000, 1600) \n",
      " The shape of X_test is : (3000, 1600)\n"
     ]
    }
   ],
   "source": [
    "if X_tr.shape[1]==X_ts.shape[1]:\n",
    "    print('The shape of X_train is :',X_tr.shape,'\\n','The shape of X_test is :',X_ts.shape)\n",
    "else:\n",
    "    print('Please change the max_features hyper paramter in the Tfidf vectorizer and run the code again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "- Machine Learning supervised algorithm to classify the positive and negative statemnts\n",
    "- In this the default threshold taken as 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', solver='liblinear')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Logr=LogisticRegression(solver ='liblinear',class_weight='balanced')\n",
    "Logr.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results report  Logistic includes Accuracy, F1 Score, Confusion matrix\n",
    "- Accuracy= TP+TN/(TP+TN+FP+FN)\n",
    "- Precision= TP/(TP+FP)\n",
    "- Recall= TP/(TP+FN)\n",
    "- F1 Score= 2*(PrecisionxRecall)/(Precision+Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.42      0.58      0.49      1010\n",
      "        True       0.74      0.60      0.66      1990\n",
      "\n",
      "    accuracy                           0.59      3000\n",
      "   macro avg       0.58      0.59      0.58      3000\n",
      "weighted avg       0.63      0.59      0.60      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[ 585  425]\n",
      " [ 792 1198]] \n",
      "\n",
      "The F1_score of the model on test _data_set: 0.6631608081926378 \n",
      "\n",
      "The accuracy_score of the model on test _data_set: 0.5943333333333334\n"
     ]
    }
   ],
   "source": [
    "y_pred=Logr.predict(X_ts)\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The F1_score of the model on test _data_set:',f1_score(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The accuracy_score of the model on test _data_set:',accuracy_score(y_pred,y_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree classifier\n",
    "- _Intially performing Randomized Search on the pramaters available in the DecisionTree Model_\n",
    "- _Also in Randomzed Search N-iterations has been taken only 5 due to memory constrains_\n",
    "-  _u can good to go with higher iterations_\n",
    "- _After getting best paramters those have to be substituted in to the algorithm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   30.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_iter=8,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [8, 10, 12, 14, 16, 18, 20,\n",
       "                                                      22, 24, 26, 28, 30, 32,\n",
       "                                                      34, 36, 38, 40, 42, 44,\n",
       "                                                      46, 48, 50, 52, 54, 56,\n",
       "                                                      58, 60, 62, 64, 66, ...],\n",
       "                                        'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8,\n",
       "                                                           9, 10, 11, 12, 13,\n",
       "                                                           14, 15, 16, 17, 18,\n",
       "                                                           19, 20, 21, 22, 23,\n",
       "                                                           24, 25, 26, 27, 28,\n",
       "                                                           29, 30, 31, ...],\n",
       "                                        'min_samples_split': [2, 3, 4, 5]},\n",
       "                   random_state=42, verbose=3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4, 5],'max_depth':list(range(8, 100,2))}\n",
    "dt = DecisionTreeClassifier()\n",
    "clf=RandomizedSearchCV(estimator = dt, param_distributions = params, n_iter = 8, cv = 5,\\\n",
    "                               verbose=3, random_state=42, n_jobs = -1)\n",
    "\n",
    "clf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the below  best classifer fit for the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=92, max_leaf_nodes=98, min_samples_split=4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=92, max_leaf_nodes=98, min_samples_split=4)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "Dt=DecisionTreeClassifier(max_depth=92, max_leaf_nodes=98,min_samples_split=4 )\n",
    "Dt.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results report  Decision Tree includes Accuracy, F1 Score, Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.38      0.59      0.46       880\n",
      "        True       0.78      0.60      0.67      2120\n",
      "\n",
      "    accuracy                           0.59      3000\n",
      "   macro avg       0.58      0.59      0.57      3000\n",
      "weighted avg       0.66      0.59      0.61      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[ 519  361]\n",
      " [ 858 1262]] \n",
      "\n",
      "The F1_score of the model on test _data_set: 0.6743254074271974 \n",
      "\n",
      "The accuracy_score of the model on test _data_set: 0.5936666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred=Dt.predict(X_ts)\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The F1_score of the model on test _data_set:',f1_score(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The accuracy_score of the model on test _data_set:',accuracy_score(y_pred,y_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation on Train Dataset\n",
    "- _Checking the cross validation on the Train dataset_.\n",
    "- _The model is performing well  on Train data set because it is trained on 70% of observations_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  16.4s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=  19.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  14.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  15.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  16.2s\n",
      "Accuracy Mean 0.8344285714285714 Accuracy Variance      0.0024074713637646616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "Dt=DecisionTreeClassifier()\n",
    "accuracies = cross_val_score(estimator = Dt, X = X_tr,\\\n",
    "     y = y_tr, cv = 5,verbose=2)\n",
    "print(\"Accuracy Mean {} Accuracy Variance \\\n",
    "     {}\".format(accuracies.mean(),accuracies.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classifier\n",
    "- _Intially performing Randomized Search on the pramaters available in the Random_forest Model.\n",
    "- _Also in Randomzed Search N_iterations has been taken only 5 due to memory constrains_. \n",
    "-  _You can good to go with higher iterations_.\n",
    "- _After getting best paramters those have to be substituted in to the algorithm_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  2.1min remaining:   39.9s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [2],\n",
       "                                        'max_features': [20, 28, 37, 46, 55, 64,\n",
       "                                                         73, 82, 91, 100],\n",
       "                                        'min_samples_leaf': [2, 3, 4, 5, 6, 7,\n",
       "                                                             8, 9],\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        'n_estimators': [100, 109, 118, 127,\n",
       "                                                         136, 145, 154, 163,\n",
       "                                                         172, 181, 190, 200,\n",
       "                                                         209, 218, 227, 236,\n",
       "                                                         245, 254, 263, 272,\n",
       "                                                         281, 290, 300, 309,\n",
       "                                                         318, 327, 336, 345,\n",
       "                                                         354, 363, ...]},\n",
       "                   random_state=42, verbose=3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 100)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [int(x) for x in np.linspace(start = 20, stop = 100, num = 10)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 100, num = 1)]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3,4,5,6, 7,8,9,10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [ 2, 3,4,5,6,7,8,9]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "params = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = params, n_iter = 5, cv = 5,\\\n",
    "                               verbose=3, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=2, max_features=91,\n",
       "                       min_samples_leaf=4, min_samples_split=7,\n",
       "                       n_estimators=390)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=2, max_features=91,\n",
       "                       min_samples_leaf=4, min_samples_split=7,\n",
       "                       n_estimators=390)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF=RandomForestClassifier(bootstrap=False, max_depth=2, max_features=91,\n",
    "                       min_samples_leaf=4, min_samples_split=7,\n",
    "                       n_estimators=390)\n",
    "RF.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results report  Random Forest includes Accuracy, F1 Score, Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.01      0.83      0.03        23\n",
      "        True       1.00      0.54      0.70      2977\n",
      "\n",
      "    accuracy                           0.55      3000\n",
      "   macro avg       0.51      0.68      0.37      3000\n",
      "weighted avg       0.99      0.55      0.70      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[  19    4]\n",
      " [1358 1619]] \n",
      "\n",
      "The F1_score of the model on test _data_set: 0.7039130434782609 \n",
      "\n",
      "The accuracy_score of the model on test _data_set: 0.546\n"
     ]
    }
   ],
   "source": [
    "y_pred=RF.predict(X_ts)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The F1_score of the model on test _data_set:',f1_score(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The accuracy_score of the model on test _data_set:',accuracy_score(y_pred,y_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Mean 0.91425 Accuracy Variance      0.007988272654335235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "accuracies = cross_val_score(estimator = RF, X = X_tr,\\\n",
    "     y = y_tr, cv = 5)\n",
    "print(\"Accuracy Mean {} Accuracy Variance \\\n",
    "     {}\".format(accuracies.mean(),accuracies.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, gamma=10)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf',C=1,gamma=10)\n",
    "svc.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results Support Vector Machines Accuracy,F1_Score Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00         1\n",
      "        True       1.00      0.54      0.70      2999\n",
      "\n",
      "    accuracy                           0.54      3000\n",
      "   macro avg       0.50      0.27      0.35      3000\n",
      "weighted avg       1.00      0.54      0.70      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[   0    1]\n",
      " [1377 1622]] \n",
      "\n",
      "The F1_score of the model on test _data_set: 0.7018606663781913 \n",
      "\n",
      "The accuracy_score of the model on test _data_set: 0.5406666666666666\n"
     ]
    }
   ],
   "source": [
    "y_pred=svc.predict(X_ts)\n",
    "\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The F1_score of the model on test _data_set:',f1_score(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The accuracy_score of the model on test _data_set:',accuracy_score(y_pred,y_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "\n",
    "navby=MultinomialNB()\n",
    "navby.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results Support Vector Machines Accuracy,F1_Score< Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.38      0.55      0.45       950\n",
      "        True       0.74      0.59      0.65      2050\n",
      "\n",
      "    accuracy                           0.58      3000\n",
      "   macro avg       0.56      0.57      0.55      3000\n",
      "weighted avg       0.63      0.58      0.59      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[ 527  423]\n",
      " [ 850 1200]] \n",
      "\n",
      "The F1_score of the model on test _data_set: 0.6534168254832561 \n",
      "\n",
      "The accuracy_score of the model on test _data_set: 0.5756666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred=navby.predict(X_ts)\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The F1_score of the model on test _data_set:',f1_score(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The accuracy_score of the model on test _data_set:',accuracy_score(y_pred,y_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation for Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "Accuracy Mean 0.9302857142857144 Accuracy Variance      0.00926921611286188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "accuracies = cross_val_score(estimator = navby, X = X_tr,\\\n",
    "     y = y_tr, cv = 7,verbose=2)\n",
    "print(\"Accuracy Mean {} Accuracy Variance \\\n",
    "     {}\".format(accuracies.mean(),accuracies.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost classifier\n",
    "- _Intially performing Randomized Search on the pramaters available in the XG Boost Model.\n",
    "- _Also in Randomzed Search N_iterations has been taken only 5 due to memory constrains_. \n",
    "-  _You can good to go with higher iterations_.\n",
    "- _After getting best paramters those have to be substituted in to the algorithm_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  5.3min remaining:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100,...\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.01, 0.05, 0.1, 0.15,\n",
       "                                                          0.2, 0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'reg_alpha': [1, 3, 5, 7, 10],\n",
       "                                        'reg_lambda': [1, 3, 5, 7, 10]},\n",
       "                   scoring='f1_macro', verbose=3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Hyper Parameter Optimization\n",
    "import xgboost as xgb\n",
    "params={\n",
    " \"learning_rate\"    : [0.01,0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ],\n",
    "    \"reg_alpha\"     : [1,3,5,7,10],\n",
    "     \"reg_lambda\"   : [1,3,5,7,10]\n",
    "}\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "classifier=xgb.XGBClassifier()\n",
    "random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='f1_macro',n_jobs=-1,cv=5,verbose=3)\n",
    "random_search.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best Estimator after hyper paramter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.4, gamma=0.2, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.3, max_delta_step=0, max_depth=12,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=7, reg_lambda=10, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\dask\\config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\distributed\\config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.4, eval_metric='error',\n",
       "              gamma=0.0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.2, max_delta_step=0,\n",
       "              max_depth=7, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=3, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf = xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.4, eval_metric='error',\n",
    "              gamma=0.0, gpu_id=-1, importance_type='gain',\n",
    "              interaction_constraints='', learning_rate=0.2, max_delta_step=0,\n",
    "              max_depth=7, min_child_weight=5,\n",
    "             num_parallel_tree=1, random_state=0, reg_alpha=3, reg_lambda=1,\n",
    "              scale_pos_weight=1, subsample=1, tree_method='exact',\n",
    "              validate_parameters=1, verbosity=None)\n",
    "\n",
    "\n",
    "clf.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results XG Boost Accuracy,F1_Score< Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.37      0.59      0.46       868\n",
      "        True       0.78      0.60      0.68      2132\n",
      "\n",
      "    accuracy                           0.59      3000\n",
      "   macro avg       0.58      0.59      0.57      3000\n",
      "weighted avg       0.66      0.59      0.61      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[ 515  353]\n",
      " [ 862 1270]] \n",
      "\n",
      "The f1_score of the model: 0.6764314247669774\n",
      "The accuracy_score of the model: 0.595\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(X_ts)\n",
    "\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "\n",
    "print('The f1_score of the model:',f1_score(y_pred,y_ts))\n",
    "\n",
    "\n",
    "print('The accuracy_score of the model:',accuracy_score(y_pred,y_ts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validarion on Train dataset XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  2.6min remaining:   49.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  2.4min remaining:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  5.7min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  3.2min remaining:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  4.7min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8812935332752637"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(random_search, X_tr, y_tr, cv=5, scoring='f1_macro')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Topic Modelling</center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070000</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares Sneha, when i call some i hear you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070001</th>\n",
       "      <td>False</td>\n",
       "      <td>@336024 We apologies for the trouble. We would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070002</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares u irritating idiots, y the fuck pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070003</th>\n",
       "      <td>False</td>\n",
       "      <td>@307570 Sorry we gave you a chance of being up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070004</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares He told me - Sir don't repeat your...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text\n",
       "2070000     True  @idea_cares Sneha, when i call some i hear you...\n",
       "2070001    False  @336024 We apologies for the trouble. We would...\n",
       "2070002     True  @idea_cares u irritating idiots, y the fuck pr...\n",
       "2070003    False  @307570 Sorry we gave you a chance of being up...\n",
       "2070004     True  @idea_cares He told me - Sir don't repeat your..."
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking the total number of observations and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "twd_sample['text']=twd_sample['text'].apply(remove_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Text data after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070000</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care sneha call hear irritating unlimited...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070001</th>\n",
       "      <td>False</td>\n",
       "      <td>apology trouble would like inform pca reverse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070002</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care u irritating idiot fuck precall anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070003</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry gave chance upset service weve noted con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070004</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care told sir dont repeat issue followed ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text\n",
       "2070000     True  idea care sneha call hear irritating unlimited...\n",
       "2070001    False  apology trouble would like inform pca reverse ...\n",
       "2070002     True  idea care u irritating idiot fuck precall anno...\n",
       "2070003    False  sorry gave chance upset service weve noted con...\n",
       "2070004     True  idea care told sir dont repeat issue followed ..."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Considering only the Negative topics in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070001</th>\n",
       "      <td>False</td>\n",
       "      <td>apology trouble would like inform pca reverse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070003</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry gave chance upset service weve noted con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070008</th>\n",
       "      <td>False</td>\n",
       "      <td>troy sorry disappointing experience hope give ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070010</th>\n",
       "      <td>False</td>\n",
       "      <td>time feed need molly deliciousness awaits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070012</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry inconvenience checked offer applicable h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text\n",
       "2070001    False  apology trouble would like inform pca reverse ...\n",
       "2070003    False  sorry gave chance upset service weve noted con...\n",
       "2070008    False  troy sorry disappointing experience hope give ...\n",
       "2070010    False          time feed need molly deliciousness awaits\n",
       "2070012    False  sorry inconvenience checked offer applicable h..."
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample_negative=twd_sample[twd_sample['inbound']==False]\n",
    "twd_sample_negative.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Considering only the Positive topics in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070000</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care sneha call hear irritating unlimited...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070002</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care u irritating idiot fuck precall anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070004</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care told sir dont repeat issue followed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070005</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care darshan tried seek help one supervis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070006</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care darshan extremely serious issue firs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text\n",
       "2070000     True  idea care sneha call hear irritating unlimited...\n",
       "2070002     True  idea care u irritating idiot fuck precall anno...\n",
       "2070004     True  idea care told sir dont repeat issue followed ...\n",
       "2070005     True  idea care darshan tried seek help one supervis...\n",
       "2070006     True  idea care darshan extremely serious issue firs..."
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample_positive=twd_sample[twd_sample['inbound']==True]\n",
    "twd_sample_positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    \n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intial check of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apology',\n",
       " 'trouble',\n",
       " 'would',\n",
       " 'like',\n",
       " 'inform',\n",
       " 'pca',\n",
       " 'reverse',\n",
       " 'pca',\n",
       " 'playing',\n",
       " 'someone',\n",
       " 'try',\n",
       " 'call',\n",
       " 'regardssneha']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(twd_sample_negative.iloc[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf Vectorizer with unigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_idf_vectorizer      =     TfidfVectorizer(stop_words = 'english',max_features=2000, min_df=0.0005,\\\n",
    "                                      max_df=0.99,tokenizer = tokenize)\n",
    "term_idf_matrix          =     term_idf_vectorizer.fit_transform(twd_sample_negative.text) \n",
    "term_idf_feature_names   =     term_idf_vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Negative Matrix Factorization\n",
    "- NNMF is an unsuperviser algorithm that performs dimensionality reduction and clustering\n",
    "- We use this in conjuction with TF-IDF to model topics across documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='nndsvd', n_components=15, random_state=22)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model=NMF(n_components=15,init='nndsvd',random_state=22)\n",
    "nmf_model.fit(term_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 15 words for topic # 0\n",
      "['r', 'info', 'use', 'f', 'information', 'woafwenp', 'check', 'j', 'h', 'wkjhdxwgrq', 'c', 'u', 'link', 'tco', 'http']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 1\n",
      "['linked', 'associated', 'apologize', 'right', 'look', 'trouble', 'amp', 'connect', 'send', 'account', 'u', 'follow', 'dm', 'address', 'email']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 2\n",
      "['device', 'happened', 'aw', 'try', 'sure', 'follow', 'resolved', 'additional', 'twitter', 'going', 'question', 'letting', 'u', 'let', 'know']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 3\n",
      "['frustration', 'oh', 'way', 'really', 'order', 'tell', 'caused', 'trouble', 'inconvenience', 'delay', 'experience', 'store', 'im', 'hear', 'sorry']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 4\n",
      "['shortly', 'right', 'contact', 'member', 'possible', 'support', 'patience', 'share', 'soon', 'appreciate', 'feedback', 'connect', 'touch', 'note', 'team']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 5\n",
      "['ah', 'fine', 'ticket', 'speak', 'wish', 'andy', 'nice', 'colleague', 'start', 'longer', 'haha', 'staff', 'friend', 'service', 'pa']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 6\n",
      "['travelling', 'problem', 'currently', 'late', 'journey', 'minute', 'check', 'train', 'josh', 'delay', 'lewis', 'andy', 'apology', 'service', 'hi']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 7\n",
      "['ive', 'ill', 'hey', 'time', 'tweeting', 'u', 'head', 'card', 'love', 'feedback', 'letting', 'sharing', 'reaching', 'store', 'thanks']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 8\n",
      "['look', 'acct', 'follow', 'clr', 'hello', 'better', 'instruction', 'twitter', 'note', 'dm', 'direct', 'message', 'u', 'assist', 'send']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 9\n",
      "['hr', 'working', 'ur', 'rgds', 'resolved', 'idea', 'response', 'experiencing', 'released', 'resolve', 'io', 'provide', 'device', 'update', 'issue']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 10\n",
      "['happy', 'country', 'io', 'version', 'continue', 'closer', 'want', 'meet', 'like', 'u', 'wed', 'ypt', 'gdrqu', 'dm', 'look']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 11\n",
      "['provide', 'card', 'package', 'sxpdictw', 'order', 'service', 'happy', 'account', 'address', 'look', 'wkjhdxwgrq', 'tracking', 'dm', 'phone', 'number']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 12\n",
      "['able', 'glad', 'seeing', 'love', 'enjoy', 'time', 'thats', 'day', 'soon', 'flight', 'hope', 'great', 'gabe', 'welcome', 'youre']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 13\n",
      "['happened', 'id', 'amy', 'question', 'tell', 'best', 'glad', 'wed', 'clr', 'going', 'acct', 'whats', 'info', 'happy', 'help']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 14\n",
      "['jw', 'hear', 'woafwenp', 'c', 'glad', 'thank', 'contact', 'hey', 'free', 'u', 'da', 'feel', 'dm', 'assistance', 'need']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, topic in enumerate(nmf_model.components_):\n",
    "    print(f\"The top 15 words for topic # {index}\")\n",
    "    print([term_idf_feature_names[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf Vectorizer with bigrams anfd tri grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results=nmf_model.transform(term_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4572, 2000)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_idf_vectorizer     = TfidfVectorizer(max_df=0.99, max_features=2000,min_df=0.0005,\\\n",
    "                                          stop_words='english', use_idf=True, tokenizer=tokenize, ngram_range=(2,3))\n",
    "term_idf_matrix         = term_idf_vectorizer.fit_transform(twd_sample_negative.text) \n",
    "term_idf_feature_names  = term_idf_vectorizer.get_feature_names()\n",
    "term_idf_matrix.shape\n",
    "\n",
    "nmf_model=NMF(n_components=15,init='nndsvd',random_state=22)\n",
    "nmf_model.fit(term_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 15 words for topic # 0\n",
      "['send dm', 'inconvenience caused', 'update available', 'hear send', 'inconvience caused', 'weve got', 'delivery date', 'issue device', 'http tco e', 'welcome let', 'connect u', 'u phone chat', 'let work', 'twitter english help', 'id love']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 1\n",
      "['letting know', 'assistance thank', 'apple music', 'sound good', 'link provided', 'u know send', 'apologize trouble send', 'dm store', 'tco jojkltck', 'account info', 'u phone chat', 'help u', 'follow prompt', 'address account', 'glad able']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 2\n",
      "['fb http tco', 'http tco ibiy', 'best help', 'u make', 'tracking number delivery', 'help u', 'sorry hear follow', 'address ac http', 'u note http', 'hi tony', 'season official', 'let know issue', 'u phone chat', 'let know', 'know issue persists']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 3\n",
      "['hi dm u', 'order number', 'want make', 'send zip', 'persists http', 'u account email', 'critical response line', 'u know send', 'inapp support', 'english help spanish', 'hear email', 'thanks love', 'im happy', 'http tco mbymxn', 'team following email']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 4\n",
      "['tco py z', 'sound good', 'dm u address', 'mcribfinderapp io android', 'regarding concern', 'tracking number', 'prior updating http', 'tco nrhudiek', 'team follow', 'assist clr', 'help jw http', 'dm store', 'u help', 'number link', 'ty jayne']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 5\n",
      "['address look http', 'help provide', 'u dm da', 'tell u help', 'wed recommend', 'apology inconvenience', 'number contact', 'dm da', 'thanks bringing attention', 'link ill arrange', 'http tco exwzpnpj', 'thank patience', 'hi debbie', 'tco lnmcdqt', 'phone assist']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 6\n",
      "['u know dm', 'resolve ur', 'dont want', 'known issue atm', 'ive replied', 'ml http tco', 'delivery date', 'u issue', 'ive passed', 'english help spanish', 'let know store', 'apology inconvenience', 'appreciate feedback', 'tco lnmcdqt', 'http tco qc']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 7\n",
      "['issue atm', 'im glad', 'http tco q', 'u dm http', 'u note', 'u phone chat', 'http tco luv', 'contact u dm', 'locate account', 'help jw http', 'let know issue', 'tco oczyrx', 'send u email', 'thanks love', 'u confirmation number']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 8\n",
      "['link provided', 'account information', 'help u', 'dm check', 'http tco oodr', 'check article', 'information tell', 'u note http', 'number link', 'follow prompt', 'figure whats', 'member team following', 'u phone chat', 'assistance regard', 'tco jojkltck']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 9\n",
      "['id like help', 'weve sent dm', 'understand frustration', 'sorry trouble caused', 'sorry hear follow', 'ill check', 'sorry hear send', 'hear enjoyed', 'signalling issue', 'sorry hear feel', 'io info check', 'rgds ganesh', 'fb http tco', 'u whats going', 'io version']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 10\n",
      "['http tco jpi', 'dm u store', 'io info check', 'ur issue', 'dm u confirmation', 'dm barcode', 'w dx becky', 'mcribfinderapp io', 'let sure device', 'u phone chat', 'way improve', 'youll need', 'hi send', 'follow prompt', 'link provided']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 11\n",
      "['rgds ganesh', 'contact u dm', 'phone chat', 'trouble send u', 'persists http', 'tco lnmcdqt', 'http tco jpi', 'account info', 'address account', 'link provided', 'welcome let', 'u info', 'follow prompt', 'question let', 'oh im']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 12\n",
      "['access account', 'hi thanks', 'tco h iouehc', 'locate account', 'going send', 'u dm http', 'u contact', 'email amp', 'team follow', 'help send u', 'hvorx rh team', 'hope great flight', 'hi known issue', 'way soon', 'youd like']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 13\n",
      "['http tco ibiy', 'ill best help', 'apology disruption', 'season official', 'u account email', 'chat team', 'hi thanks', 'way improve', 'dm check', 'hi tony', 'account information', 'wed happy look', 'inconvenience caused', 'http tco jpi', 'http tco p']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 14\n",
      "['je vous', 'http tco mbymxn', 'weve got', 'connect u', 'hi thanks', 'u confirmation', 'dm u address', 'http tco q', 'hi claire', 'u phone chat', 'dx becky', 'help let', 'follow prompt', 'assistance send', 'number assistance']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, topic in enumerate(nmf_model.components_):\n",
    "    print(f\"The top 15 words for topic # {index}\")\n",
    "    print([term_idf_feature_names[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "twd_sample_negative['Topic']=topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070001</th>\n",
       "      <td>False</td>\n",
       "      <td>apology trouble would like inform pca reverse ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070003</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry gave chance upset service weve noted con...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070008</th>\n",
       "      <td>False</td>\n",
       "      <td>troy sorry disappointing experience hope give ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070010</th>\n",
       "      <td>False</td>\n",
       "      <td>time feed need molly deliciousness awaits</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070012</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry inconvenience checked offer applicable h...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text  Topic\n",
       "2070001    False  apology trouble would like inform pca reverse ...     10\n",
       "2070003    False  sorry gave chance upset service weve noted con...      3\n",
       "2070008    False  troy sorry disappointing experience hope give ...      3\n",
       "2070010    False          time feed need molly deliciousness awaits     14\n",
       "2070012    False  sorry inconvenience checked offer applicable h...      3"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample_negative.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People related to topic 4 are segregated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070045</th>\n",
       "      <td>False</td>\n",
       "      <td>apology trouble request share complete address...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070084</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry problem service understand frustrating f...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070122</th>\n",
       "      <td>False</td>\n",
       "      <td>oh dear sorry chris feedback logged passed mar...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070150</th>\n",
       "      <td>False</td>\n",
       "      <td>hi richard escalated store maintenance team sm...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070160</th>\n",
       "      <td>False</td>\n",
       "      <td>get food online team look smaira</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070199</th>\n",
       "      <td>False</td>\n",
       "      <td>account security team would best able assist c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070465</th>\n",
       "      <td>False</td>\n",
       "      <td>hey ross team looking currently please stay tu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070578</th>\n",
       "      <td>False</td>\n",
       "      <td>apologize trouble send u note http tco eyc uue...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070580</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry trouble send u note http tco juscquh tea...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070582</th>\n",
       "      <td>False</td>\n",
       "      <td>take look send u note via http tco tv psvy sr ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070586</th>\n",
       "      <td>False</td>\n",
       "      <td>currently reviewing email touch shortly apprec...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070588</th>\n",
       "      <td>False</td>\n",
       "      <td>dont currently offer phone support weve notifi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070590</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry hear experience please send u note http ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070592</th>\n",
       "      <td>False</td>\n",
       "      <td>appreciate letting u know member team touch vi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070603</th>\n",
       "      <td>False</td>\n",
       "      <td>help follow http tco jbfrao team connect right...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070607</th>\n",
       "      <td>False</td>\n",
       "      <td>apologize trouble connect u http tco kgixas cx...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070609</th>\n",
       "      <td>False</td>\n",
       "      <td>wed happy take look please share detail http t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070611</th>\n",
       "      <td>False</td>\n",
       "      <td>help follow http tco mn w aa team connect righ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070634</th>\n",
       "      <td>False</td>\n",
       "      <td>help send u note via http tco h iouehc team as...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070645</th>\n",
       "      <td>False</td>\n",
       "      <td>help send u note http tco f rq nq team connect</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070647</th>\n",
       "      <td>False</td>\n",
       "      <td>help send u note via http tco f rq nq team assist</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070653</th>\n",
       "      <td>False</td>\n",
       "      <td>hi jessica sorry delay weve requested member t...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070678</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry confusion send u note http tco h iouehc ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070682</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry hear please contact u via http tco e hvo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070688</th>\n",
       "      <td>False</td>\n",
       "      <td>hi send u note http tco ohfgxsay team able help</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070690</th>\n",
       "      <td>False</td>\n",
       "      <td>weve escalated support inquiry appropriate tea...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070692</th>\n",
       "      <td>False</td>\n",
       "      <td>hi manoj member team touch via email please ch...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070696</th>\n",
       "      <td>False</td>\n",
       "      <td>let take closer look send u note via http tco ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070700</th>\n",
       "      <td>False</td>\n",
       "      <td>hi see outreach member team following via emai...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070713</th>\n",
       "      <td>False</td>\n",
       "      <td>weve received dm member team reached please re...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079162</th>\n",
       "      <td>False</td>\n",
       "      <td>bonjour sol e dapprendre cela lavezvous signal...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079171</th>\n",
       "      <td>False</td>\n",
       "      <td>michele el proceso de devoluci n compra del nu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079211</th>\n",
       "      <td>False</td>\n",
       "      <td>informed earlier support team working issue up...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079259</th>\n",
       "      <td>False</td>\n",
       "      <td>thanks letting u know emily please also share ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079273</th>\n",
       "      <td>False</td>\n",
       "      <td>switching ntc workout plan isnt feature ntc ap...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079308</th>\n",
       "      <td>False</td>\n",
       "      <td>oh wed hate lose mary feedback youd like leave...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079316</th>\n",
       "      <td>False</td>\n",
       "      <td>hi chris sorry please speak onboard team able ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079459</th>\n",
       "      <td>False</td>\n",
       "      <td>would love help specialized team handle imovie...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079470</th>\n",
       "      <td>False</td>\n",
       "      <td>want sure everything place get new iphone x re...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079480</th>\n",
       "      <td>False</td>\n",
       "      <td>wed happy get pointed right direction help pho...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079502</th>\n",
       "      <td>False</td>\n",
       "      <td>depends upon revert come relevant team update ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079504</th>\n",
       "      <td>False</td>\n",
       "      <td>request rest assure done soon regard amruta</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079539</th>\n",
       "      <td>False</td>\n",
       "      <td>baggage team reunited bag way quickly</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079547</th>\n",
       "      <td>False</td>\n",
       "      <td>speak ticket counter gate team review earlier ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079575</th>\n",
       "      <td>False</td>\n",
       "      <td>another great example showcasing team trained ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079584</th>\n",
       "      <td>False</td>\n",
       "      <td>appreciate shoutout crew aateam</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079587</th>\n",
       "      <td>False</td>\n",
       "      <td>appreciate including u travel plan tyler aatea...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079614</th>\n",
       "      <td>False</td>\n",
       "      <td>well forward app team respond back info share</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079626</th>\n",
       "      <td>False</td>\n",
       "      <td>safety crew customer unable offer food drink a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079636</th>\n",
       "      <td>False</td>\n",
       "      <td>please speak baggage agent airport call baggag...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079647</th>\n",
       "      <td>False</td>\n",
       "      <td>good morning jesse loving pic appreciate inclu...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079672</th>\n",
       "      <td>False</td>\n",
       "      <td>fan delay either thank carlos appreciate loyalty</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079684</th>\n",
       "      <td>False</td>\n",
       "      <td>dont want upset anyone maintenance team finish...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079686</th>\n",
       "      <td>False</td>\n",
       "      <td>experiencing maintenance delay well headed rea...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079688</th>\n",
       "      <td>False</td>\n",
       "      <td>see youve left gate area well wheel soon pilot...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079703</th>\n",
       "      <td>False</td>\n",
       "      <td>seamless travel goal appreciate patience well ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079705</th>\n",
       "      <td>False</td>\n",
       "      <td>weve got best biz thrilled ride sky way rock a...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079767</th>\n",
       "      <td>False</td>\n",
       "      <td>amazing hear michael team shine</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079898</th>\n",
       "      <td>False</td>\n",
       "      <td>appreciate reaching verify disabling wifi via ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079978</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry jobbie ill sure feed back buying team sm...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>338 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text  Topic\n",
       "2070045    False  apology trouble request share complete address...      4\n",
       "2070084    False  sorry problem service understand frustrating f...      4\n",
       "2070122    False  oh dear sorry chris feedback logged passed mar...      4\n",
       "2070150    False  hi richard escalated store maintenance team sm...      4\n",
       "2070160    False                   get food online team look smaira      4\n",
       "2070199    False  account security team would best able assist c...      4\n",
       "2070465    False  hey ross team looking currently please stay tu...      4\n",
       "2070578    False  apologize trouble send u note http tco eyc uue...      4\n",
       "2070580    False  sorry trouble send u note http tco juscquh tea...      4\n",
       "2070582    False  take look send u note via http tco tv psvy sr ...      4\n",
       "2070586    False  currently reviewing email touch shortly apprec...      4\n",
       "2070588    False  dont currently offer phone support weve notifi...      4\n",
       "2070590    False  sorry hear experience please send u note http ...      4\n",
       "2070592    False  appreciate letting u know member team touch vi...      4\n",
       "2070603    False  help follow http tco jbfrao team connect right...      4\n",
       "2070607    False  apologize trouble connect u http tco kgixas cx...      4\n",
       "2070609    False  wed happy take look please share detail http t...      4\n",
       "2070611    False  help follow http tco mn w aa team connect righ...      4\n",
       "2070634    False  help send u note via http tco h iouehc team as...      4\n",
       "2070645    False     help send u note http tco f rq nq team connect      4\n",
       "2070647    False  help send u note via http tco f rq nq team assist      4\n",
       "2070653    False  hi jessica sorry delay weve requested member t...      4\n",
       "2070678    False  sorry confusion send u note http tco h iouehc ...      4\n",
       "2070682    False  sorry hear please contact u via http tco e hvo...      4\n",
       "2070688    False    hi send u note http tco ohfgxsay team able help      4\n",
       "2070690    False  weve escalated support inquiry appropriate tea...      4\n",
       "2070692    False  hi manoj member team touch via email please ch...      4\n",
       "2070696    False  let take closer look send u note via http tco ...      4\n",
       "2070700    False  hi see outreach member team following via emai...      4\n",
       "2070713    False  weve received dm member team reached please re...      4\n",
       "...          ...                                                ...    ...\n",
       "2079162    False  bonjour sol e dapprendre cela lavezvous signal...      4\n",
       "2079171    False  michele el proceso de devoluci n compra del nu...      4\n",
       "2079211    False  informed earlier support team working issue up...      4\n",
       "2079259    False  thanks letting u know emily please also share ...      4\n",
       "2079273    False  switching ntc workout plan isnt feature ntc ap...      4\n",
       "2079308    False  oh wed hate lose mary feedback youd like leave...      4\n",
       "2079316    False  hi chris sorry please speak onboard team able ...      4\n",
       "2079459    False  would love help specialized team handle imovie...      4\n",
       "2079470    False  want sure everything place get new iphone x re...      4\n",
       "2079480    False  wed happy get pointed right direction help pho...      4\n",
       "2079502    False  depends upon revert come relevant team update ...      4\n",
       "2079504    False        request rest assure done soon regard amruta      4\n",
       "2079539    False              baggage team reunited bag way quickly      4\n",
       "2079547    False  speak ticket counter gate team review earlier ...      4\n",
       "2079575    False  another great example showcasing team trained ...      4\n",
       "2079584    False                    appreciate shoutout crew aateam      4\n",
       "2079587    False  appreciate including u travel plan tyler aatea...      4\n",
       "2079614    False      well forward app team respond back info share      4\n",
       "2079626    False  safety crew customer unable offer food drink a...      4\n",
       "2079636    False  please speak baggage agent airport call baggag...      4\n",
       "2079647    False  good morning jesse loving pic appreciate inclu...      4\n",
       "2079672    False   fan delay either thank carlos appreciate loyalty      4\n",
       "2079684    False  dont want upset anyone maintenance team finish...      4\n",
       "2079686    False  experiencing maintenance delay well headed rea...      4\n",
       "2079688    False  see youve left gate area well wheel soon pilot...      4\n",
       "2079703    False  seamless travel goal appreciate patience well ...      4\n",
       "2079705    False  weve got best biz thrilled ride sky way rock a...      4\n",
       "2079767    False                    amazing hear michael team shine      4\n",
       "2079898    False  appreciate reaching verify disabling wifi via ...      4\n",
       "2079978    False  sorry jobbie ill sure feed back buying team sm...      4\n",
       "\n",
       "[338 rows x 3 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample_negative[twd_sample_negative['Topic']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
