{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Twitter topic classification Hackathon\n",
    "- Sentiment Classification\n",
    "- Topic Modelling\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all the standard libraries , \n",
    "## Pandas, numpy arrays, Regular Expression, NLTK for text processing, Sklearn for Classifiction models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score,f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the CSV file from the Local PC \n",
    "- Data set has been read in to the DataFrame variable twd(Twitter Data)\n",
    "- Please paste the link of your file in the same function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twd=pd.read_csv(r'C:/Users/pc/Desktop/Hackathon/twcs/twcs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Displaying first five observations of the table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of the original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2811774, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here in this Data set we need the text data and either it is a good or bad statement by customer\n",
    "  - ##### Hence discarding the rest of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'author_id', 'inbound', 'created_at', 'text',\n",
       "       'response_tweet_id', 'in_response_to_tweet_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropping the unecessary columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "twd.drop(['tweet_id', 'author_id', 'created_at','response_tweet_id', 'in_response_to_tweet_id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####   Dataset after removing the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inbound                                               text\n",
       "0    False  @115712 I understand. I would like to assist y...\n",
       "1     True      @sprintcare and how do you propose we do that\n",
       "2     True  @sprintcare I have sent several private messag...\n",
       "3    False  @115712 Please send us a Private Message so th...\n",
       "4     True                                 @sprintcare I did."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking the total number of observations and columns present in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2811774, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Only Ten thousand observations has been taken to develope the model. \n",
    "######  The New data frame variable name  is \"twd_sample \"(twitter data Sample) consisting 10,000 observations.\n",
    "######  It restricted because of memory limitations , if it is not so, u can pass the whole data set like \"\"\" twd.iloc[:,:].copy() \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "twd_sample=twd.iloc[2070000:2080000,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070000</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares Sneha, when i call some i hear you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070001</th>\n",
       "      <td>False</td>\n",
       "      <td>@336024 We apologies for the trouble. We would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070002</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares u irritating idiots, y the fuck pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070003</th>\n",
       "      <td>False</td>\n",
       "      <td>@307570 Sorry we gave you a chance of being up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070004</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares He told me - Sir don't repeat your...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text\n",
       "2070000     True  @idea_cares Sneha, when i call some i hear you...\n",
       "2070001    False  @336024 We apologies for the trouble. We would...\n",
       "2070002     True  @idea_cares u irritating idiots, y the fuck pr...\n",
       "2070003    False  @307570 Sorry we gave you a chance of being up...\n",
       "2070004     True  @idea_cares He told me - Sir don't repeat your..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking whether our dataset consists of NaNs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inbound    0\n",
       "text       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Counting the number of Postive and Negative comments avialable in the DataFrame  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     5428\n",
       "False    4572\n",
       "Name: inbound, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample['inbound'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Writing the generalised function to remove the uncessary characters, stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_noise(input_text):\n",
    "    \n",
    "    lema=WordNetLemmatizer()                                ### World Lematizer \n",
    "\n",
    "    input_text = re.sub('<.*?>', ' ', (input_text))         ### Removing html and xml tags in text data and replacing with blanks\n",
    "    input_text = str(input_text).replace(\"<br />\", \" \")     ###  Removing Line Breakage tags\n",
    "    input_text = str(input_text).replace(\",\", \"\")           ### Removing punctuations and replacing with blanks\n",
    "    input_text = str(input_text).replace(\"\\'\" ,\"\")\n",
    "    input_text = str(input_text).replace(\"\\\\\", \"\")\n",
    "    input_text = str(input_text).replace(\"-\", \"\")\n",
    "    input_text = str(input_text).replace(\".\", \"\")\n",
    "    input_text  =re.sub(r'\\s+', ' ',input_text )            ### Removing multiple spaces\n",
    "     \n",
    "    \n",
    "    input_text = re.sub(\"[^a-zA-Z]\",\" \",input_text)         ## Considering only alphabets rest is replaced by spaces\n",
    "    input_text = input_text.lower()                         ## Lowering the text\n",
    "    words      = input_text.split()                         ## Splitting the text\n",
    "    noise_free_words =  [w for w in words if w not in set(stopwords.words('english'))] ## Removing Stop words\n",
    "    lower_words=[lema.lemmatize(w) for w in noise_free_words]                          ## Applying Lematization to the words                        \n",
    "    lower_words=' '.join(lower_words)\n",
    "                                   \n",
    "    return lower_words   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the Data into 70% Train, 30% Test by passing text data in to  \n",
    "##### Independent variable \"X\" and True or False in to Targer variable \"y\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=twd_sample['text'].iloc[:7000]\n",
    "y_train=twd_sample['inbound'].iloc[:7000]\n",
    "\n",
    "X_test=twd_sample['text'].iloc[7000:10000]\n",
    "y_test=twd_sample['inbound'].iloc[7000:10000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the Training independent variable X_train (7000,) \n",
      "\n",
      "The shape of the Testing independent variable X_test (3000,) \n",
      "\n",
      "The shape of the Taining dependent variable y_train (7000,) \n",
      "\n",
      "The shape of the Testing dependent variable y_test (3000,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the Training independent variable X_train',X_train.shape,'\\n')\n",
    "print('The shape of the Testing independent variable X_test',X_test.shape,'\\n')\n",
    "print('The shape of the Taining dependent variable y_train',y_train.shape,'\\n')\n",
    "print('The shape of the Testing dependent variable y_test',y_test.shape,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing the noise in the Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.apply(remove_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2070000    idea care sneha call hear irritating unlimited...\n",
       "2070001    apology trouble would like inform pca reverse ...\n",
       "2070002    idea care u irritating idiot fuck precall anno...\n",
       "2070003    sorry gave chance upset service weve noted con...\n",
       "2070004    idea care told sir dont repeat issue followed ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Removing the noise in the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=X_test.apply(remove_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2077000    im sorry inconvenience shared detail using lin...\n",
       "2077001                            worst sale service amazon\n",
       "2077002    certainly understand frustration id mad thank ...\n",
       "2077003    amazonhelp hey ive already spoken someone cust...\n",
       "2077004    im sorry filter box strange confirm order ship...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting of words in the observations to matrix representation using TF-IDF Vectorizer\n",
    "- Word Frequencies with TfidfVectorizer.\n",
    "- This stands for “Term Frequency – Inverse Document Frequency\" which are the components of the resulting -  scores assigned to each word.\n",
    "- Inverse Document Frequency: This downscales words that appear a lot across documents.\n",
    "- max_df,min_df, n-grams are hyper parmaters, after working on several random data, i have fixed the paramters.\n",
    "- To the get best min_df,max_df, max_features, This can be done by using a Random Search CV using  Pipe Line.\n",
    "- To reduce the complexity of code , i have done it seperately.\n",
    "\n",
    "**`max_df`**` : float in range [0.0, 1.0] or int, default=1.0`<br>\n",
    "When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None.\n",
    "\n",
    "**`min_df`**` : float in range [0.0, 1.0] or int, default=1`<br>\n",
    "When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_tr=X_train\n",
    "X_ts=X_test\n",
    "y_tr=y_train\n",
    "y_ts=y_test\n",
    "\n",
    "tf=TfidfVectorizer(max_df=0.85, min_df=3,max_features=1800,ngram_range=(1, 1), stop_words='english')\n",
    "\n",
    "X_tr=tf.fit_transform(X_tr).toarray()\n",
    "\n",
    "X_ts=tf.fit_transform(X_ts).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ##### Note if X_train and X_test column \"(m,n)\"  \"(k,n)\" dimension is not matching, \n",
    "  - please change the max_features in TF-IDF Vectorizer paramter in the above.\n",
    "  - Remember please give high features  to learn more from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is : (7000, 1800) \n",
      " The shape of X_test is : (3000, 1800)\n"
     ]
    }
   ],
   "source": [
    "if X_tr.shape[1]==X_ts.shape[1]:\n",
    "    print('The shape of X_train is :',X_tr.shape,'\\n','The shape of X_test is :',X_ts.shape)\n",
    "else:\n",
    "    print('Please change the max_features hyper paramter in the Tfidf vectorizer and run the code again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE:\n",
    "#### X_tr, X_ts are the TF-IDF matrices trained on the repective observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out of these  algorithms which ever we get  good accuracy and F1 score is choosen\n",
    "- Currently my models used in this Notebook has went up to 57% accuracy on an average with different Records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "- Machine Learning supervised algorithm to classify the positive and negative statemnts\n",
    "- In this the default threshold taken as 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', solver='liblinear')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "Logr=LogisticRegression(solver ='liblinear',class_weight='balanced')\n",
    "Logr.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results report  Logistic includes Accuracy, F1 Score, Confusion matrix\n",
    "- Accuracy= TP+TN/(TP+TN+FP+FN)\n",
    "- Precision= TP/(TP+FP)\n",
    "- Recall= TP/(TP+FN)\n",
    "- F1 Score= 2*(PrecisionxRecall)/(Precision+Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.47      0.66      0.55       974\n",
      "        True       0.80      0.64      0.71      2026\n",
      "\n",
      "    accuracy                           0.65      3000\n",
      "   macro avg       0.63      0.65      0.63      3000\n",
      "weighted avg       0.69      0.65      0.66      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[ 645  329]\n",
      " [ 733 1293]] \n",
      "\n",
      "The F1_score of the model on test _data_set: 0.7088815789473685 \n",
      "\n",
      "The accuracy_score of the model on test _data_set: 0.646\n"
     ]
    }
   ],
   "source": [
    "y_pred=Logr.predict(X_ts)\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The F1_score of the model on test _data_set:',f1_score(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The accuracy_score of the model on test _data_set:',accuracy_score(y_pred,y_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree classifier\n",
    "- _Intially performing Randomized Search on the pramaters available in the DecisionTree Model_.\n",
    "- _Also in Randomzed Search N-iterations has been taken only 5 due to memory constrains_.\n",
    "-  _u can good to go with higher iterations_.\n",
    "- _After getting best paramters those have to be substituted in to the algorithm_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   59.6s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_iter=8,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'max_depth': [8, 10, 12, 14, 16, 18, 20,\n",
       "                                                      22, 24, 26, 28, 30, 32,\n",
       "                                                      34, 36, 38, 40, 42, 44,\n",
       "                                                      46, 48, 50, 52, 54, 56,\n",
       "                                                      58, 60, 62, 64, 66, ...],\n",
       "                                        'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8,\n",
       "                                                           9, 10, 11, 12, 13,\n",
       "                                                           14, 15, 16, 17, 18,\n",
       "                                                           19, 20, 21, 22, 23,\n",
       "                                                           24, 25, 26, 27, 28,\n",
       "                                                           29, 30, 31, ...],\n",
       "                                        'min_samples_split': [2, 3, 4, 5]},\n",
       "                   random_state=42, verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4, 5],'max_depth':list(range(8, 100,2))}\n",
    "dt = DecisionTreeClassifier()\n",
    "clf=RandomizedSearchCV(estimator = dt, param_distributions = params, n_iter = 8, cv = 5,\\\n",
    "                               verbose=3, random_state=42, n_jobs = -1)\n",
    "\n",
    "clf.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the below  best classifer fit for the Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=64, max_leaf_nodes=79)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=64, max_leaf_nodes=79)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "Dt=DecisionTreeClassifier(max_depth=64, max_leaf_nodes=79)\n",
    "\n",
    "Dt.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results report  Decision Tree includes Accuracy, F1 Score, Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.42      0.65      0.51       893\n",
      "        True       0.81      0.62      0.70      2107\n",
      "\n",
      "    accuracy                           0.63      3000\n",
      "   macro avg       0.62      0.64      0.61      3000\n",
      "weighted avg       0.69      0.63      0.65      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[ 584  309]\n",
      " [ 794 1313]] \n",
      "\n",
      "The F1_score of the model on test _data_set: 0.7042102440332528 \n",
      "\n",
      "The accuracy_score of the model on test _data_set: 0.6323333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred=Dt.predict(X_ts)\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The F1_score of the model on test _data_set:',f1_score(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The accuracy_score of the model on test _data_set:',accuracy_score(y_pred,y_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validation on Train Dataset\n",
    "- _Checking the cross validation on the Train dataset_.\n",
    "- _The model is performing well on Train data set because it has 70% of observations_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  16.4s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................. , total=  19.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  14.2s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  15.6s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=  16.2s\n",
      "Accuracy Mean 0.8344285714285714 Accuracy Variance      0.0024074713637646616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "Dt=DecisionTreeClassifier()\n",
    "accuracies = cross_val_score(estimator = Dt, X = X_tr,\\\n",
    "     y = y_tr, cv = 5,verbose=2)\n",
    "print(\"Accuracy Mean {} Accuracy Variance \\\n",
    "     {}\".format(accuracies.mean(),accuracies.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest classifier\n",
    "- _Intially performing Randomized Search on the pramaters available in the Random forest Model_.\n",
    "- _Also in Randomzed Search N-iterations has been taken only 5 due to memory constrains_. \n",
    "-  _You can good to go with higher iterations_.\n",
    "- _After getting best paramters those have to be substituted in to the algorithm_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  2.0min remaining:   38.4s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [2],\n",
       "                                        'max_features': [20, 28, 37, 46, 55, 64,\n",
       "                                                         73, 82, 91, 100],\n",
       "                                        'min_samples_leaf': [2, 3, 4, 5, 6, 7,\n",
       "                                                             8, 9],\n",
       "                                        'min_samples_split': [2, 3, 4, 5, 6, 7,\n",
       "                                                              8, 9, 10],\n",
       "                                        'n_estimators': [100, 109, 118, 127,\n",
       "                                                         136, 145, 154, 163,\n",
       "                                                         172, 181, 190, 200,\n",
       "                                                         209, 218, 227, 236,\n",
       "                                                         245, 254, 263, 272,\n",
       "                                                         281, 290, 300, 309,\n",
       "                                                         318, 327, 336, 345,\n",
       "                                                         354, 363, ...]},\n",
       "                   random_state=42, verbose=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 100)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [int(x) for x in np.linspace(start = 20, stop = 100, num = 10)]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(2, 100, num = 1)]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3,4,5,6, 7,8,9,10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [ 2, 3,4,5,6,7,8,9]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "params = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = params, n_iter = 5, cv = 5,\\\n",
    "                               verbose=3, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=2, max_features=91,\n",
       "                       min_samples_leaf=4, min_samples_split=7,\n",
       "                       n_estimators=390)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, max_depth=2, max_features=91,\n",
       "                       min_samples_leaf=4, min_samples_split=7,\n",
       "                       n_estimators=390)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF=RandomForestClassifier(bootstrap=False, max_depth=2, max_features=91,\n",
    "                       min_samples_leaf=4, min_samples_split=7,\n",
    "                       n_estimators=390)\n",
    "RF.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Results report  Random Forest includes Accuracy, F1 Score, Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.01      0.86      0.03        22\n",
      "        True       1.00      0.54      0.70      2978\n",
      "\n",
      "    accuracy                           0.55      3000\n",
      "   macro avg       0.51      0.70      0.37      3000\n",
      "weighted avg       0.99      0.55      0.70      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[  19    3]\n",
      " [1359 1619]] \n",
      "\n",
      "The F1_score of the model on test _data_set: 0.7039130434782609 \n",
      "\n",
      "The accuracy_score of the model on test _data_set: 0.546\n"
     ]
    }
   ],
   "source": [
    "y_pred=RF.predict(X_ts)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The F1_score of the model on test _data_set:',f1_score(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The accuracy_score of the model on test _data_set:',accuracy_score(y_pred,y_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Mean 0.91425 Accuracy Variance      0.007988272654335235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "accuracies = cross_val_score(estimator = RF, X = X_tr,\\\n",
    "     y = y_tr, cv = 5)\n",
    "print(\"Accuracy Mean {} Accuracy Variance \\\n",
    "     {}\".format(accuracies.mean(),accuracies.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel='rbf',C=1)\n",
    "svc.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results Support Vector Machines Accuracy,F1_Score Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.43      0.66      0.52       891\n",
      "        True       0.81      0.62      0.71      2109\n",
      "\n",
      "    accuracy                           0.64      3000\n",
      "   macro avg       0.62      0.64      0.61      3000\n",
      "weighted avg       0.70      0.64      0.65      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[ 587  304]\n",
      " [ 791 1318]] \n",
      "\n",
      "The F1_score of the model on test _data_set: 0.706512999195926 \n",
      "\n",
      "The accuracy_score of the model on test _data_set: 0.635\n"
     ]
    }
   ],
   "source": [
    "y_pred=svc.predict(X_ts)\n",
    "\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The F1_score of the model on test _data_set:',f1_score(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The accuracy_score of the model on test _data_set:',accuracy_score(y_pred,y_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive bayes MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "\n",
    "navby=MultinomialNB()\n",
    "navby.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results MultiNomialNB Accuracy,F1_Score< Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.39      0.62      0.48       871\n",
      "        True       0.80      0.61      0.69      2129\n",
      "\n",
      "    accuracy                           0.61      3000\n",
      "   macro avg       0.59      0.61      0.58      3000\n",
      "weighted avg       0.68      0.61      0.63      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[ 539  332]\n",
      " [ 839 1290]] \n",
      "\n",
      "The F1_score of the model on test _data_set: 0.6878165822447347 \n",
      "\n",
      "The accuracy_score of the model on test _data_set: 0.6096666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred=navby.predict(X_ts)\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The F1_score of the model on test _data_set:',f1_score(y_pred,y_ts),'\\n')\n",
    "\n",
    "print('The accuracy_score of the model on test _data_set:',accuracy_score(y_pred,y_ts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation for Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.1s\n",
      "Accuracy Mean 0.9302857142857144 Accuracy Variance      0.00926921611286188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "accuracies = cross_val_score(estimator = navby, X = X_tr,\\\n",
    "     y = y_tr, cv = 7,verbose=2)\n",
    "print(\"Accuracy Mean {} Accuracy Variance \\\n",
    "     {}\".format(accuracies.mean(),accuracies.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost classifier\n",
    "- _Intially performing Randomized Search on the pramaters available in the XG Boost Model.\n",
    "- _Also in Randomzed Search N_iterations has been taken only 5 due to memory constrains_. \n",
    "-  _You can good to go with higher iterations_.\n",
    "- _After getting best paramters those have to be substituted in to the algorithm_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  3.8min remaining:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None, gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100,...\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5,\n",
       "                                                             0.7],\n",
       "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
       "                                        'learning_rate': [0.01, 0.05, 0.1, 0.15,\n",
       "                                                          0.2, 0.25, 0.3],\n",
       "                                        'max_depth': [3, 4, 5, 6, 8, 10, 12,\n",
       "                                                      15],\n",
       "                                        'min_child_weight': [1, 3, 5, 7],\n",
       "                                        'reg_alpha': [1, 3, 5, 7, 10],\n",
       "                                        'reg_lambda': [1, 3, 5, 7, 10]},\n",
       "                   scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Hyper Parameter Optimization\n",
    "import xgboost as xgb\n",
    "params={\n",
    " \"learning_rate\"    : [0.01,0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
    " \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
    " \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    " \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
    " \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ],\n",
    "    \"reg_alpha\"     : [1,3,5,7,10],\n",
    "     \"reg_lambda\"   : [1,3,5,7,10]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "classifier=xgb.XGBClassifier()\n",
    "\n",
    "random_search=RandomizedSearchCV(classifier,param_distributions=params,n_iter=5,scoring='roc_auc',n_jobs=-1,cv=5,verbose=3)\n",
    "random_search.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Best Estimator after hyper paramter tuning\n",
    "- In this estimator remove \"missing=nan\" paramter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5, gamma=0.2, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.25, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=1, reg_lambda=10, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5, gamma=0.2, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.25, max_delta_step=0, max_depth=10,\n",
       "              min_child_weight=3, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=1, reg_lambda=10, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "clf=xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=0.5, gamma=0.2, gpu_id=-1,\n",
    "              importance_type='gain', interaction_constraints='',\n",
    "              learning_rate=0.25, max_delta_step=0, max_depth=10,\n",
    "              min_child_weight=3,  monotone_constraints='()',\n",
    "              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n",
    "              reg_alpha=1, reg_lambda=10, scale_pos_weight=1, subsample=1,\n",
    "              tree_method='exact', validate_parameters=1, verbosity=None)\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(X_tr,y_tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Results XG Boost Accuracy,F1_Score Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.35      0.68      0.46       709\n",
      "        True       0.86      0.61      0.71      2291\n",
      "\n",
      "    accuracy                           0.62      3000\n",
      "   macro avg       0.60      0.64      0.59      3000\n",
      "weighted avg       0.74      0.62      0.65      3000\n",
      " \n",
      "Confusion Matrix : \n",
      " [[ 481  228]\n",
      " [ 897 1394]] \n",
      "\n",
      "The f1_score of the model: 0.7124968055200613\n",
      "The accuracy_score of the model: 0.625\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf.predict(X_ts)\n",
    "\n",
    "\n",
    "print(classification_report(y_pred,y_ts),end=\" \\n\")\n",
    "\n",
    "print('Confusion Matrix :','\\n',confusion_matrix(y_pred,y_ts),'\\n')\n",
    "\n",
    "\n",
    "print('The f1_score of the model:',f1_score(y_pred,y_ts))\n",
    "\n",
    "\n",
    "print('The accuracy_score of the model:',accuracy_score(y_pred,y_ts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross validarion on Train dataset XG Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  2.6min remaining:   49.5s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  2.4min remaining:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  5.7min remaining:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  7.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  3.2min remaining:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  19 out of  25 | elapsed:  4.7min remaining:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8812935332752637"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(random_search, X_tr, y_tr, cv=5, scoring='f1_macro')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- All base libraries are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070000</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares Sneha, when i call some i hear you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070001</th>\n",
       "      <td>False</td>\n",
       "      <td>@336024 We apologies for the trouble. We would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070002</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares u irritating idiots, y the fuck pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070003</th>\n",
       "      <td>False</td>\n",
       "      <td>@307570 Sorry we gave you a chance of being up...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070004</th>\n",
       "      <td>True</td>\n",
       "      <td>@idea_cares He told me - Sir don't repeat your...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text\n",
       "2070000     True  @idea_cares Sneha, when i call some i hear you...\n",
       "2070001    False  @336024 We apologies for the trouble. We would...\n",
       "2070002     True  @idea_cares u irritating idiots, y the fuck pr...\n",
       "2070003    False  @307570 Sorry we gave you a chance of being up...\n",
       "2070004     True  @idea_cares He told me - Sir don't repeat your..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Checking the total number of observations and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "twd_sample['text']=twd_sample['text'].apply(remove_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Text data after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070000</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care sneha call hear irritating unlimited...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070001</th>\n",
       "      <td>False</td>\n",
       "      <td>apology trouble would like inform pca reverse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070002</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care u irritating idiot fuck precall anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070003</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry gave chance upset service weve noted con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070004</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care told sir dont repeat issue followed ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text\n",
       "2070000     True  idea care sneha call hear irritating unlimited...\n",
       "2070001    False  apology trouble would like inform pca reverse ...\n",
       "2070002     True  idea care u irritating idiot fuck precall anno...\n",
       "2070003    False  sorry gave chance upset service weve noted con...\n",
       "2070004     True  idea care told sir dont repeat issue followed ..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Considering only the Negative topics in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070001</th>\n",
       "      <td>False</td>\n",
       "      <td>apology trouble would like inform pca reverse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070003</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry gave chance upset service weve noted con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070008</th>\n",
       "      <td>False</td>\n",
       "      <td>troy sorry disappointing experience hope give ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070010</th>\n",
       "      <td>False</td>\n",
       "      <td>time feed need molly deliciousness awaits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070012</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry inconvenience checked offer applicable h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text\n",
       "2070001    False  apology trouble would like inform pca reverse ...\n",
       "2070003    False  sorry gave chance upset service weve noted con...\n",
       "2070008    False  troy sorry disappointing experience hope give ...\n",
       "2070010    False          time feed need molly deliciousness awaits\n",
       "2070012    False  sorry inconvenience checked offer applicable h..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample_negative=twd_sample[twd_sample['inbound']==False]\n",
    "twd_sample_negative.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Considering only the Positive topics in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070000</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care sneha call hear irritating unlimited...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070002</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care u irritating idiot fuck precall anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070004</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care told sir dont repeat issue followed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070005</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care darshan tried seek help one supervis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070006</th>\n",
       "      <td>True</td>\n",
       "      <td>idea care darshan extremely serious issue firs...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text\n",
       "2070000     True  idea care sneha call hear irritating unlimited...\n",
       "2070002     True  idea care u irritating idiot fuck precall anno...\n",
       "2070004     True  idea care told sir dont repeat issue followed ...\n",
       "2070005     True  idea care darshan tried seek help one supervis...\n",
       "2070006     True  idea care darshan extremely serious issue firs..."
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample_positive=twd_sample[twd_sample['inbound']==True]\n",
    "twd_sample_positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    \n",
    "    filtered_tokens = []\n",
    "    \n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Intial check of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apology',\n",
       " 'trouble',\n",
       " 'would',\n",
       " 'like',\n",
       " 'inform',\n",
       " 'pca',\n",
       " 'reverse',\n",
       " 'pca',\n",
       " 'playing',\n",
       " 'someone',\n",
       " 'try',\n",
       " 'call',\n",
       " 'regardssneha']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(twd_sample_negative.iloc[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tfidf Vectorizer with unigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_idf_vectorizer      =     TfidfVectorizer(stop_words = 'english',max_features=2000, min_df=0.0005,\\\n",
    "                                      max_df=0.99,tokenizer = tokenize)\n",
    "term_idf_matrix          =     term_idf_vectorizer.fit_transform(twd_sample_negative.text) \n",
    "term_idf_feature_names   =     term_idf_vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non Negative Matrix Factorization\n",
    "- NNMF is an unsuperviser algorithm that performs dimensionality reduction and clustering\n",
    "- We use this in conjuction with TF-IDF to model topics across documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='nndsvd', n_components=15, random_state=22)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model=NMF(n_components=15,init='nndsvd',random_state=22)\n",
    "nmf_model.fit(term_idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Printing out the Top 15 Topics involved in the entire documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 15 words for topic # 0\n",
      "['r', 'info', 'use', 'f', 'information', 'woafwenp', 'check', 'j', 'h', 'wkjhdxwgrq', 'c', 'u', 'link', 'tco', 'http']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 1\n",
      "['linked', 'associated', 'apologize', 'right', 'look', 'trouble', 'amp', 'connect', 'send', 'account', 'u', 'follow', 'dm', 'address', 'email']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 2\n",
      "['device', 'happened', 'aw', 'try', 'sure', 'follow', 'resolved', 'additional', 'twitter', 'going', 'question', 'letting', 'u', 'let', 'know']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 3\n",
      "['frustration', 'oh', 'way', 'really', 'order', 'tell', 'caused', 'trouble', 'inconvenience', 'delay', 'experience', 'store', 'im', 'hear', 'sorry']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 4\n",
      "['shortly', 'right', 'contact', 'member', 'possible', 'support', 'patience', 'share', 'soon', 'appreciate', 'feedback', 'connect', 'touch', 'note', 'team']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 5\n",
      "['ah', 'fine', 'ticket', 'speak', 'wish', 'andy', 'nice', 'colleague', 'start', 'longer', 'haha', 'staff', 'friend', 'service', 'pa']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 6\n",
      "['travelling', 'problem', 'currently', 'late', 'journey', 'minute', 'check', 'train', 'josh', 'delay', 'lewis', 'andy', 'apology', 'service', 'hi']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 7\n",
      "['ive', 'ill', 'hey', 'time', 'tweeting', 'u', 'head', 'card', 'love', 'feedback', 'letting', 'sharing', 'reaching', 'store', 'thanks']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 8\n",
      "['look', 'acct', 'follow', 'clr', 'hello', 'better', 'instruction', 'twitter', 'note', 'dm', 'direct', 'message', 'u', 'assist', 'send']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 9\n",
      "['hr', 'working', 'ur', 'rgds', 'resolved', 'idea', 'response', 'experiencing', 'released', 'resolve', 'io', 'provide', 'device', 'update', 'issue']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 10\n",
      "['happy', 'country', 'io', 'version', 'continue', 'closer', 'want', 'meet', 'like', 'u', 'wed', 'ypt', 'gdrqu', 'dm', 'look']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 11\n",
      "['provide', 'card', 'package', 'sxpdictw', 'order', 'service', 'happy', 'account', 'address', 'look', 'wkjhdxwgrq', 'tracking', 'dm', 'phone', 'number']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 12\n",
      "['able', 'glad', 'seeing', 'love', 'enjoy', 'time', 'thats', 'day', 'soon', 'flight', 'hope', 'great', 'gabe', 'welcome', 'youre']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 13\n",
      "['happened', 'id', 'amy', 'question', 'tell', 'best', 'glad', 'wed', 'clr', 'going', 'acct', 'whats', 'info', 'happy', 'help']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 14\n",
      "['jw', 'hear', 'woafwenp', 'c', 'glad', 'thank', 'contact', 'hey', 'free', 'u', 'da', 'feel', 'dm', 'assistance', 'need']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, topic in enumerate(nmf_model.components_):\n",
    "    print(f\"The top 15 words for topic # {index}\")\n",
    "    print([term_idf_feature_names[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorizer with bigrams and tri grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results=nmf_model.transform(term_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(init='nndsvd', n_components=15, random_state=22)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_idf_vectorizer     = TfidfVectorizer(max_df=0.99, max_features=2000,min_df=0.0005,\\\n",
    "                                          stop_words='english', use_idf=True, tokenizer=tokenize, ngram_range=(2,3))\n",
    "term_idf_matrix         = term_idf_vectorizer.fit_transform(twd_sample_negative.text) \n",
    "term_idf_feature_names  = term_idf_vectorizer.get_feature_names()\n",
    "term_idf_matrix.shape\n",
    "\n",
    "nmf_model=NMF(n_components=15,init='nndsvd',random_state=22)\n",
    "nmf_model.fit(term_idf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 15 words for topic # 0\n",
      "['help http', 'help http tco', 'qui http tco', 'information http', 'information http tco', 'check http', 'check http tco', 'dm http tco', 'dm http', 'hope help', 'http tco c', 'tco c', 'link http', 'link http tco', 'http tco']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 1\n",
      "['whats going', 'need assistance', 'help let', 'need help', 'help let u', 'know assistance', 'u know question', 'know question', 'know help', 'u know help', 'know need', 'u know need', 'u know', 'let u know', 'let u']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 2\n",
      "['dm assist', 'u dm assist', 'email address follow', 'address follow', 'address connect', 'email address connect', 'help send', 'help send u', 'u dm email', 'dm email', 'dm email address', 'email address', 'send u', 'send u dm', 'u dm']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 3\n",
      "['let know', 'im sorry inconvenience', 'im sorry delay', 'sorry inconvenience caused', 'tell u', 'hi im', 'hi im sorry', 'oh im', 'oh im sorry', 'sorry frustration', 'im sorry frustration', 'sorry inconvenience', 'inconvenience caused', 'im sorry hear', 'im sorry']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 4\n",
      "['u dm http', 'io version', 'look http', 'look http tco', 'want help', 'u dm', 'meet u dm', 'meet u', 'dm http tco', 'dm http', 'http tco', 'tco gdrqu ypt', 'gdrqu ypt', 'http tco gdrqu', 'tco gdrqu']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 5\n",
      "['free dm', 'feel free dm', 'dm u look', 'u look', 'u email address', 'follow dm u', 'dm u account', 'u account', 'dm u email', 'follow dm', 'u email', 'help dm u', 'help dm', 'email address', 'dm u']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 6\n",
      "['trouble send', 'trouble send u', 'sorry trouble', 'look send', 'look send u', 'team touch', 'team connect', 'help send u', 'help send', 'send u', 'note http tco', 'u note', 'u note http', 'note http', 'send u note']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 7\n",
      "['hear youre', 'hello sorry', 'received email', 'http tco sxpdictw', 'tco sxpdictw', 'u email', 'sorry hear experience', 'hear experience', 'hear dm u', 'hi sorry hear', 'hear dm', 'sorry hear dm', 'hi sorry', 'im sorry hear', 'sorry hear']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 8\n",
      "['look send', 'look send u', 'twitter instruction', 'message twitter', 'direct message twitter', 'message twitter instruction', 'sent direct', 'sent direct message', 'send u', 'message assist', 'direct message assist', 'send u direct', 'u direct message', 'u direct', 'direct message']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 9\n",
      "['touch dm', 'great weekend', 'u posted', 'store manager', 'appreciate patience', 'thank letting u', 'thank letting', 'internal review', 'team http tco', 'team http', 'u know', 'thanks letting u', 'thanks letting', 'letting u', 'letting u know']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 10\n",
      "['use link dm', 'km http tco', 'km http', 'dm tracking number', 'use link', 'ml http', 'ml http tco', 'phone number', 'dm tracking', 'u tracking number', 'dm u tracking', 'u tracking', 'tracking number', 'tco wkjhdxwgrq', 'http tco wkjhdxwgrq']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 11\n",
      "['pyldjbc r', 'http tco pyldjbc', 'io version', 'thanks reaching', 'help way', 'like help way', 'whats going', 'wed like look', 'like look', 'dm record', 'dm record locator', 'record locator', 'wed like help', 'like help', 'wed like']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 12\n",
      "['look internet', 'phone assist clr', 'hi happy help', 'hi happy', 'acct phone assist', 'assist clr', 'phone assist', 'happy help look', 'help look', 'acct phone', 'dm acct phone', 'send dm acct', 'dm acct', 'send dm', 'happy help']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 13\n",
      "['dm u http', 'youre welcome', 'reach u http', 'reach u', 'jzp hla b', 'jzp hla', 'http tco jzp', 'hla b', 'tco jzp', 'tco jzp hla', 'contact u http', 'contact u', 'make sure', 'u http tco', 'u http']\n",
      "\n",
      "\n",
      "The top 15 words for topic # 14\n",
      "['currently minute', 'issue near', 'issue near filton', 'near filton', 'signalling issue near', 'filton andy', 'follow dm', 'signalling issue', 'appreciate feedback', 'im sorry delay', 'hi sorry delay', 'hi sorry', 'minute late', 'let know', 'sorry delay']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, topic in enumerate(nmf_model.components_):\n",
    "    print(f\"The top 15 words for topic # {index}\")\n",
    "    print([term_idf_feature_names[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "twd_sample_negative['Topic']=topic_results.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inbound</th>\n",
       "      <th>text</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2070001</th>\n",
       "      <td>False</td>\n",
       "      <td>apology trouble would like inform pca reverse ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070003</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry gave chance upset service weve noted con...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070008</th>\n",
       "      <td>False</td>\n",
       "      <td>troy sorry disappointing experience hope give ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070010</th>\n",
       "      <td>False</td>\n",
       "      <td>time feed need molly deliciousness awaits</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2070012</th>\n",
       "      <td>False</td>\n",
       "      <td>sorry inconvenience checked offer applicable h...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         inbound                                               text  Topic\n",
       "2070001    False  apology trouble would like inform pca reverse ...     10\n",
       "2070003    False  sorry gave chance upset service weve noted con...      3\n",
       "2070008    False  troy sorry disappointing experience hope give ...      3\n",
       "2070010    False          time feed need molly deliciousness awaits     14\n",
       "2070012    False  sorry inconvenience checked offer applicable h...      3"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twd_sample_negative.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## People related to topic 4 are segregated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         inbound                                               text  Topic\n",
      "2070045    False  apology trouble request share complete address...      4\n",
      "2070084    False  sorry problem service understand frustrating f...      4\n",
      "2070122    False  oh dear sorry chris feedback logged passed mar...      4\n",
      "2070150    False  hi richard escalated store maintenance team sm...      4\n",
      "2070160    False                   get food online team look smaira      4 \n",
      "\n",
      "Total Number of people Related to topic \"4\" is 338\n"
     ]
    }
   ],
   "source": [
    "print(twd_sample_negative[twd_sample_negative['Topic']==4].head(),'\\n')\n",
    "\n",
    "print('Total Number of people Related to topic \"4\" is',twd_sample_negative[twd_sample_negative['Topic']==4].shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
